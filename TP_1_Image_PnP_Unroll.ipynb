{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "47337546",
      "metadata": {
        "id": "47337546"
      },
      "source": [
        "# Plug-and-Play Image Restoration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "450402ce",
      "metadata": {
        "id": "450402ce"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/esoubies/TP_INSA/blob/master/TP_1_Image_PnP_Unroll.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88703323",
      "metadata": {
        "id": "88703323"
      },
      "source": [
        "This practical session is dedicated to the implementation of plug-and-play algorithms with pre-learned denoisers.\n",
        "They will be illustrated on deblurring problems using deepinv library.\n",
        "\n",
        "The outline of the session is:\n",
        "1. Coding a blur model and testing a pretrained denoiser\n",
        "2. Implementing a PnP PGD\n",
        "3. Implementing a PnP HQS\n",
        "\n",
        "Practical informations:\n",
        "1. In torch the image format is B x C x H x W where\n",
        "  - B is the batch size\n",
        "  - C is the number of channels (C=1 for grayscale C = 3 for RGB)\n",
        "  - H is the number of pixels in the vertical direction\n",
        "  - W is the number of pixels in the horizontal direction\n",
        "2. To take advantage of the GPU acceleration, make sure to pass the `device` variable to the torch functions. For example,\n",
        "`x = torch.zeros((1,1,25,25))` creates an image of size (1,1,25,25) on the cpu than can be transfered to the GPU using `x = x.to('cuda')`.\n",
        "The image can directly by created on the GPU using `x = torch.zeros((1,1,25,25), device = 'cuda')`\n",
        "In the following code block, the variable `device` is created to easily swith from CPU to GPU. You can use it in your code instead of hard coding 'cpu' 'cuda'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93afa4ec",
      "metadata": {
        "id": "93afa4ec",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.fft import fft2, ifft2, fftshift, ifftshift\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)\n",
        "\n",
        "!pip install git+https://github.com/deepinv/deepinv.git\n",
        "import deepinv as dinv\n",
        "from deepinv.physics.generator import MotionBlurGenerator\n",
        "\n",
        "psnr = dinv.loss.PSNR()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b3baf5",
      "metadata": {
        "id": "45b3baf5"
      },
      "source": [
        "<br/><br/><br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f307d160",
      "metadata": {
        "id": "f307d160"
      },
      "source": [
        "# Part 1: Blur model and pretrained denoiser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae0fa5a",
      "metadata": {
        "id": "8ae0fa5a"
      },
      "source": [
        "## Test a pre-learned denoiser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e422d176",
      "metadata": {
        "id": "e422d176"
      },
      "source": [
        "In this section, we load an image and pretrained denoiser from the deepinv library. The denoiser is tested on a denoising problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360daab2",
      "metadata": {
        "id": "360daab2"
      },
      "outputs": [],
      "source": [
        "## Open the image\n",
        "url = dinv.utils.demo.get_image_url(\"butterfly.png\") # Other images are available here : https://huggingface.co/datasets/deepinv/images\n",
        "x0 = dinv.utils.demo.load_url_image(url, grayscale=False).to(device)\n",
        "\n",
        "# Plot image\n",
        "dinv.utils.plot(x0,'Input Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three possible denoisers in deepinv: DRUnet, DnCNN, TV.\n",
        "You can select one by commenting/decommenting the appropriate lines and play with the three during the session."
      ],
      "metadata": {
        "id": "2CqArrYzkVxA"
      },
      "id": "2CqArrYzkVxA"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the DRUNet denoiser\n",
        "# https://deepinv.github.io/deepinv/stubs/deepinv.models.DRUNet.html\n",
        "D = dinv.models.DRUNet(pretrained='download').to(device)\n",
        "\n",
        "\n",
        "# Load the DnCNN denoiser (WARNING: the proposed weights are only trained for noise level sigma = 2/255)\n",
        "# https://deepinv.github.io/deepinv/stubs/deepinv.models.DnCNN.html\n",
        "#D = dinv.models.DnCNN(pretrained='download').to(device)\n",
        "\n",
        "# TV denoiser (only in last version of deepinv)\n",
        "# Dtv = dinv.models.TVDenoiser().to(device)\n",
        "# def D(x,sigma):\n",
        "#   return Dtv(x,ths=2*sigma**2)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qamf7HmXkKMG"
      },
      "id": "Qamf7HmXkKMG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute** a noisy image\n",
        "$$ y = x_0 + \\xi $$\n",
        "where $\\xi \\sim \\mathcal{N}(0,\\sigma^2 \\mathsf{Id})$.\n",
        "\n",
        "Denoise the image $y$ by using a pre-learned denoiser for different level of noise $\\sigma^2$."
      ],
      "metadata": {
        "id": "GyYL7-Boj2ZO"
      },
      "id": "GyYL7-Boj2ZO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4448cdb4",
      "metadata": {
        "id": "4448cdb4",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "sigma = 4/255 # in [0, 0.2]\n",
        "y = ...\n",
        "\n",
        "Dy = ...\n",
        "dinv.utils.plot([y,Dy],['Noisy  (%.2f dB)'%psnr(x0,y),'Denoised (%.2f dB)'%psnr(x0,Dy)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blur model\n",
        "\n",
        "This section generates a motion blur kernel from the deepinv library."
      ],
      "metadata": {
        "id": "_pq_Q2pki46V"
      },
      "id": "_pq_Q2pki46V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "533cf4d6",
      "metadata": {
        "id": "533cf4d6",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "## Generate a motion blur\n",
        "torch.manual_seed(1)  # fix random seed for reproducibility\n",
        "generator = MotionBlurGenerator((25, 25), num_channels=1, sigma = 0.5)\n",
        "blur = generator.step(seed = 1)\n",
        "kt = blur['filter']\n",
        "\n",
        "# Embed the kernel in a MxNx3 image, and put center at pixel (0,0)\n",
        "k = torch.zeros_like(x0)\n",
        "m,n = kt.shape[-2:]\n",
        "k[:,:,0:m,0:n] = kt/torch.sum(kt)\n",
        "k = torch.roll(k,(-int(m/2),-int(n/2)),(-2,-1))\n",
        "\n",
        "# Display kernel\n",
        "dinv.utils.plot([kt, fftshift(k,dim=(-2,-1))],['Blur kernel [25 x 25]','Blur kernel [M N]'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e3c8763",
      "metadata": {
        "id": "4e3c8763"
      },
      "source": [
        "The forward model is:\n",
        "$$ y = k \\star x_0 + \\xi $$\n",
        "where $\\xi \\sim \\mathcal{N}(0,\\sigma^2 \\mathsf{Id})$ and $k$ is the generated blur kernel.\n",
        "\n",
        "Implement the code generating $y$ using the Fast Fourier Transform. (You can look at the documentation of `torch.fft.fft2`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de80a50d",
      "metadata": {
        "id": "de80a50d"
      },
      "outputs": [],
      "source": [
        "sigma = 0.1#2/255  # noise level\n",
        "\n",
        "# Draw a sample of the direct model for image deblurring (apply blur and add Gaussian noise)\n",
        "y = ...\n",
        "\n",
        "dinv.utils.plot(y,'Blur and noisy image')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b48bcce3",
      "metadata": {
        "id": "b48bcce3"
      },
      "source": [
        "# Part 2: Image deblurring with PnP-PGD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46c2925",
      "metadata": {
        "id": "c46c2925"
      },
      "source": [
        "In this section, you will implement a PnP proximal gradient descent (PnP-PGD) to solve the deblurring problem. The iteration is given by :\n",
        "$$ x_{k+1} = D_\\eta \\circ (\\operatorname{Id} - \\tau \\nabla f) (x_k) $$\n",
        "where\n",
        "- $f$ is the data fidelity term defined by $f(x) = \\frac{1}{2\\sigma^2} \\|k \\star x - y\\|_2^2$.\n",
        "- $D_\\eta$ is the denoiser of level $\\eta$\n",
        "- $\\tau$ is the step-size and should be chosen such that $\\tau < \\frac{2}{L}$ with $L$ the Lipschitz constant of $\\nabla f$.\n",
        "\n",
        "Complete the following cell to\n",
        "1. Implement PnP-PGD iteration\n",
        "2. Store the PSNR of the reconstruction at each iteration\n",
        "\n",
        "Try to find the best $\\tau$ and $\\eta$ and number of iterations. Test the other denoisers and comment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tau =  # step-size\n",
        "eta =  # strength of the denoiser\n",
        "\n",
        "# initialize with blurry image\n",
        "x = y.clone()\n",
        "\n",
        "psnrtab = []  # to store psnr\n",
        "\n",
        "niter =  # number of iterations\n",
        "t0 = time.time()\n",
        "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0.,psnr(x0,y)))\n",
        "\n",
        "for it in range(niter):\n",
        "    # before calling the denoiser, use with torch.no_grad() to avoid computing the gradient with respect to the weights of the denoising network\n",
        "    with torch.no_grad():\n",
        "      x = # PnP-PGD iteration\n",
        "\n",
        "    psnrtab.append(psnr(x0,x))\n",
        "\n",
        "    if (it+1)%10==0:\n",
        "        print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(it+1,niter,time.time()-t0,psnrtab[it]))\n",
        "        dinv.utils.plot(x,'Iteration %i'%it)\n",
        "\n",
        "plt.plot(torch.tensor(psnrtab))\n",
        "plt.title('PSNR')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JfjbzrzHpfvu"
      },
      "id": "JfjbzrzHpfvu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bacb760d",
      "metadata": {
        "id": "bacb760d"
      },
      "source": [
        "# Part 3: Image deblurring with PnP-HQS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, you will implement a PnP Half Quadratic Splitting (PnP-HQS) to solve the deblurring problem. The iteration is given by :\n",
        "$$ x_{k+1} = D_{\\eta} \\circ \\mathsf{Prox}_{\\tau f} (x_k) $$\n",
        "where\n",
        "- $f$ is the data fidelity term defined by $f(x) = \\frac{1}{2\\sigma^2} \\|k \\star x - y\\|_2^2$.\n",
        "- $D_\\eta$ is the denoiser of level $\\eta$\n",
        "- $\\tau$ is the penalty parameter\n",
        "\n"
      ],
      "metadata": {
        "id": "4ijM-daSuU6Q"
      },
      "id": "4ijM-daSuU6Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before coding the PnP-HQS, we advise to create a function that implements the proximal operator of the data-fidelity term:\n",
        "$$\\mathsf{Prox}_{\\tau f}(x) = \\left(\\frac{1}{\\sigma^2} A^T A + \\tau \\mathsf{Id} \\right)^{-1} \\left( \\frac{1}{\\sigma^2} A^T y + \\tau x \\right) .$$"
      ],
      "metadata": {
        "id": "1je3jAXdu9aB"
      },
      "id": "1je3jAXdu9aB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68911bcc",
      "metadata": {
        "id": "68911bcc"
      },
      "outputs": [],
      "source": [
        "def proxf(x, tau, sigma, fAtA, fAty):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete the following cell to\n",
        "1. Implement PnP-HQS iteration\n",
        "2. Store the PSNR of the reconstruction at each iteration\n",
        "\n",
        "Try to find the best $\\tau$ and $\\eta$ and number of iterations. Test the other denoisers and comment."
      ],
      "metadata": {
        "id": "97eeenWvvE66"
      },
      "id": "97eeenWvvE66"
    },
    {
      "cell_type": "code",
      "source": [
        "tau =  # penalty parameter\n",
        "eta =  # strength of the denoiser\n",
        "\n",
        "# initialize with blurry image\n",
        "x = y.clone()\n",
        "\n",
        "psnrtab = []  # to store psnr\n",
        "rtab = []     # to store residual\n",
        "\n",
        "niter = # number of iteration\n",
        "t0 = time.time()\n",
        "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0.,psnr(x0,y)))\n",
        "\n",
        "for it in range(niter):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      x = # HQS iteration\n",
        "\n",
        "    psnrtab.append(psnr(x0,x))\n",
        "\n",
        "    if (it+1)%10==0:\n",
        "        print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(it+1,niter,time.time()-t0,psnrtab[it]))\n",
        "        dinv.utils.plot(x,'Iteration %i'%it)\n",
        "\n",
        "plt.plot(torch.tensor(psnrtab))\n",
        "plt.title('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EgRGDpG61-9V"
      },
      "id": "EgRGDpG61-9V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
